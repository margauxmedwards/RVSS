{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://github.com/rvss-australia/RVSS/blob/main/Pics/RVSS-logo-col.med.jpg?raw=1\" width=\"400\"></td>\n",
    "    <td><div align=\"left\"><font size=\"30\">Greyscale images</font></div></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "(c) Peter Corke 2024\n",
    "\n",
    "Robotics, Vision & Control: Python, see Chapter 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Jupyter environment\n",
    "We need to import some packages to help us with linear algebra (`numpy`), graphics (`matplotlib`), and machine vision (`machinevisiontoolbox`).\n",
    "If you're running locally you need to have these packages installed.  If you're running on CoLab we have to first install machinevisiontoolbox which is not preinstalled, this will be a bit slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    print('Running on CoLab')\n",
    "    !pip install machinevision-toolbox-python\n",
    "    COLAB = True\n",
    "except:\n",
    "    COLAB = False\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from machinevisiontoolbox import *\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# display result of assignments\n",
    "if COLAB:\n",
    "    %config ZMQInteractiveShell.ast_node_interactivity = 'last_expr_or_assign'\n",
    "# make NumPy display a bit nicer\n",
    "np.set_printoptions(linewidth=100, formatter={'float': lambda x: f\"{x:10.4g}\" if abs(x) > 1e-10 else f\"{0:10.4g}\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an image from data\n",
    "\n",
    "We create a 64 element vector of zeros, then set certain elements to one, then reshape it to be an 8x8 array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((64,))\n",
    "a[[17, 18, 21, 22, 25, 26, 29, 30, 41, 46, 50, 51, 52, 53]] = 1\n",
    "\n",
    "a = a.reshape((8, 8))\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some kind of pattern in here, but it's much more obvious if we display this matrix as an image -- each element of the matrix corresponds to a pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)  # display the array using Matplotlib\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can clearly see the pattern -- a face.  We can see the equivalence between a 2D NumPy array and an image.  The colors, magenta and yellow, are not part of the image, they are just the default behaviour of MatPlotLib's `imshow` method.  As you drift the cursor over the image the pixel coordinates and pixel values are displayed beneath the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also display this 2D array using the Machine Vision Toolbox for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idisp(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the result is much the same, except the colors are now just black and white.  It's a common convention that zero valued pixels are displayed as black.  `idisp` has scaled the values in the array so that the biggest value, 1, is displayed as brightest white.\n",
    "\n",
    "As you drift the cursor over the image the pixel coordinates and pixel values are displayed beneath the image. A subtle difference is that the pixel coordinates are always integers, and the datatype of the pixel is also shown.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with a real image file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"border:3px; background-color:#FF0000; padding: 1em; text-align: center;\">Note that in this section we will consider grey scale or monochrome images.  Have a look at the color-images.ipynb notebook in this folder.</p>\n",
    "\n",
    "# Images and pixels\n",
    "\n",
    "Now let's load a real greyscale image from a PNG file.  This particular image file is distributed with the Toolbox, but you can pass in the path to any image file you might have.  _If the Toolbox can't find the specified image it defaults to looking in the folder of images distributed with the Toolbox._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.Read(\"street.png\")\n",
    "# image = Image.Read(\"penguins.png\")\n",
    "# image = Image.Read(\"monalisa.png\", grey=True)  # convert original color image to greyscale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`image` is an object that contains an image, the pixel data is contained in an internal NumPy array (a python style matrix) with dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which we see has 851 columns and 1280 rows (remember NumPy always has rows as the first index).\n",
    "The data itself, the \"internal\" NumPy array can be accessed by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = image.image\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is simply a big 2-dimensional table of 8-bit integers which represent brightness of each pixel as a number between 0 (black) and 255 (white)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the value of the pixel at image coordinate (100,200), remember that's (horizontal, vertical) coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[100,200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which we see is a `uint8` datatype of value 188."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However if we index the underlying NumPy array the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array[100,200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we get a different result.  That's because for NumPy indexing the first index is the row, the second index is the column.\n",
    "\n",
    "We need to reverse the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array[200,100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is a bit of a trap for those starting out doing image processing with NumPy**  The MachineVision Toolbox is concerned with image processing so it strictly uses image coordinate indexing order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can see a lot of pertinant information about the image by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "But most importantly for an image, we can display it as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.disp();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw earlier, the notebook image view is interactive. As you move the cursor over the image, the pixel coordinates and value are updated at the bottom of the window.  The displayed pixel values are always in the range 0 to 255 which are minimum and maximum possible values for the `uint8` pixel data type.\n",
    "\n",
    "A toolbar provides some extra functionality.  You can select a region to get an expanded view, pan that selected region around, change the zoom level, or revert to the original view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:**\n",
    "\n",
    "* What's the lowest intensity value in the image?\n",
    "* What's the highest intensity value in the image?\n",
    "* What percentage of pixels have a value less than 100, or greater than 200?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms\n",
    "\n",
    "To answer some of those questions we can plot a histogram which shows the frequency (or occurence) of the various grey levels within the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = image.hist()\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is an instance of a `Histogram` object that contains statistics about the pixel values in the image.  We can plot the histogram using its `plot` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "hist.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the histogram is pretty ragged with three dominant peaks.  Explore the image with the cursor and see which parts of the image correspond to these different peaks.\n",
    "\n",
    "To answer a question like \"What percentage of pixels have a value less than 100?\" it's useful to show the normalized cumulative histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "hist.plot('ncdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that around 64% of pixels have a value less than 100.  Maybe around 10% have a value above 200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: repeat this exercise for another image, maybe `\"penguins.png\"` or `\"monalisa.png\"`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary images\n",
    "\n",
    "Let's load an image that only has two unique pixel values: 0 or 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharks = Image.Read('shark2.png')\n",
    "sharks.disp();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at another grey scale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = Image.Read(\"penguins.png\")\n",
    "penguins.disp();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. Add the code here to compute and plot the histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we see a much richer distribution of pixel values.  A lot of pixels have a value less than 100 and these are the dark background of the sign.  Clearly there are many shades of black.  Similarly for the foreground, there are many shades of white.\n",
    "\n",
    "**Q: Move the mouse over the original image to explore where these different grey levels appear.**\n",
    "\n",
    "# Thresholding\n",
    "\n",
    "A very classical image processing operation is thresholding.  We could turn the grey level image above into a binary image by comparing every pixel with a constant value called the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = Image.Read(\"penguins.png\")\n",
    "binary_image = penguins > 80\n",
    "binary_image.disp();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have only two types of pixels, black (value of 0) or white (value of 1), but they don't cleanly map to what we perceive as the black and white parts of the image.\n",
    "\n",
    "If you drift the cursor over the image you will see that the pixel datatype is now `bool`.  This is because the image was created using a logical operator `image > 80`.  The Toolbox display `False` values as black and `True` values as white.\n",
    "\n",
    "**Q: adjust the threshold in the code above to see the effect on the resulting binary image.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easier way to do this is to add a control slider to interactively set the threshold.\n",
    "\n",
    "<p style=\"border:3px; background-color:#FF0000; font-weight: bold; padding: 1em; text-align: center;\">Click the slider, don't drag it.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_image.disp()  # draw it once\n",
    "@widgets.interact\n",
    "def animate( threshold =  widgets.IntSlider(value=80, description='threshold:',  min=1, max=255)):\n",
    "    binary_image = penguins > threshold\n",
    "    binary_image.disp(reuse=True)  # draw it again with updated data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: adjust the threshold using the widget below, and explore the effect on the image.  Try to find a threshold that yields a binary image where black corresponds to the background of the sign and white corresponds to the foreground text.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges with thresholding\n",
    "\n",
    "Here is another greyscale image of a sign, but this one has a highlight due to the way the scene was lit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "castle = Image.Read(\"castle2.png\")\n",
    "castle.disp();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = castle.hist()\n",
    "plt.figure()\n",
    "hist.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram is more bimodal, that is there are two peaks.  \n",
    "\n",
    "**Q: Move the cursor over the histogram and you can read off the coordinates of the peaks.**\n",
    "\n",
    "**Q: Move the mouse over the image, explore the pixel values in the sign and background, and relate that to what you see in the histogram.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Using the widget try to find a good threshold that separates the lettering of the sign from the background**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_image = castle > 80\n",
    "binary_image.disp()\n",
    "@widgets.interact\n",
    "def animate( threshold =  widgets.IntSlider(value=80, description='threshold:',  min=1, max=255)):\n",
    "    binary_image = castle > threshold\n",
    "    binary_image.disp(reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find that it is impossible to find a single threshold that separate all letters from the background.  This is an example of the limitations of thresholding:\n",
    "\n",
    "* how do we choose the threshold?  Are there algorithms to do this?\n",
    "* how do we make thresholding robust to uneven or variable lighting conditions?\n",
    "\n",
    "**Q: Can you think of some algorithmic approaches that might segment out all the letters?**\n",
    "\n",
    "**Q: Consider a complex scene like the one below, could you find the people or motorbikes by thresholding?**\n",
    "\n",
    "<img src=\"https://petercorke.com/files/images/image3.jpg\" width=\"400\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RVSS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

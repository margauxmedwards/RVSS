{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://github.com/rvss-australia/RVSS/blob/main/Pics/RVSS-logo-col.med.jpg?raw=1\" width=\"400\"></td>\n",
    "    <td><div align=\"left\"><font size=\"30\">Spatial Operators</font></div></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "(c) Peter Corke 2024\n",
    "\n",
    "Robotics, Vision & Control: Python, see Chapter 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Jupyter environment\n",
    "We need to import some packages to help us with linear algebra (`numpy`), graphics (`matplotlib`), and machine vision (`machinevisiontoolbox`).\n",
    "If you're running locally you need to have these packages installed.  If you're running on CoLab we have to first install machinevisiontoolbox which is not preinstalled, this will be a bit slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    print('Running on CoLab')\n",
    "    !pip install machinevision-toolbox-python\n",
    "    COLAB = True\n",
    "except:\n",
    "    COLAB = False\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from machinevisiontoolbox import *\n",
    "\n",
    "# display result of assignments\n",
    "if COLAB:\n",
    "    %config ZMQInteractiveShell.ast_node_interactivity = 'last_expr_or_assign'\n",
    "# make NumPy display a bit nicer\n",
    "np.set_printoptions(linewidth=100, formatter={'float': lambda x: f\"{x:10.4g}\" if abs(x) > 1e-10 else f\"{0:10.4g}\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load a real greyscale image from a PNG file.  This particular image file is distributed with the Toolbox, but you can pass in the path to any image file you might have.  _If the Toolbox can't find the specified image it defaults to looking in the folder of images distributed with the Toolbox._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mona = Image.Read(\"monalisa.png\", mono=True)  # convert to monochrome\n",
    "mona.disp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image of the Mona Lisa looks rather grainy, the paint is cracked, but then she is over 500 years old...\n",
    "\n",
    "# Image smoothing by averaging\n",
    "\n",
    "We could smooth it out by local averaging, where every pixel in the output image is the average of all pixels in a $5 \\times 5$ window about the corresponding input pixel.  We first create a kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5),np.float32) / 25\n",
    "kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the sum of all values is equal to one.  For a given input pixel, say (20,30), the $5 \\times 5$ window is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = mona[20-2:20+3,30-2:30+3].image\n",
    "window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"border:3px; border-style:solid; border-color:#FF0000; padding: 1em;\">Note that the range 20-2:20+3 includes 20-2, 20-1, 20-0, 20+1, 20+2.  In Python the end value of  a range is not included in the set.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = window * kernel  # using element-wise multiplication\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and this is the value of pixel (20,30) in the output image.  \n",
    "\n",
    "We need do this for every pixel in the image, and we could use a pair of nested `for` loops but that's not very efficient.  We can use optimised code in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed = mona.convolve(kernel)\n",
    "smoothed.disp();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Vary the dimensions of the kernel to see what effect it has?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The square window can introduce artifact in the image, horizontal lines induced by contrast steps.  When `n` is large the monalisa develops a moustache!\n",
    "\n",
    "The problem is because the output pixel is a weighted sum of input pixels in the window, and all pixels are weighted equally irrespective of their distance from the central pixel.  We can solve this by using a symmetric kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For image smoothing it is preferable to use a kernel that is isotropic and symmetric such as a 2D Gaussian\n",
    "\n",
    "$G(u,v) = \\frac{1}{2\\pi\\sigma^2}e^{-\\frac{u^2+v^2}{2\\sigma^2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  We will create a 2D Gaussian with $\\sigma=10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = Kernel.Gauss(10)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display the kernel as a 3-dimensional mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.disp3d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can convolve the image with this kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mona.convolve(K).disp();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this more simply using the `smooth` method which accepts $\\sigma$ and the half-kernel width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mona.smooth(2, 5).disp();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Modify the code block above and look at the effect of changing $\\sigma$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding edges\n",
    "We can use 2D filtering to find edges as well.  This convolution kernel will find vertical edges.  The intuition is that each row of this kernel subtracts the pixel to the left from the pixel to the right, which will give a positive value if the intensity is increasing left to right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array( [ [1, 0, -1],\n",
    "                     [2, 0, -2],\n",
    "                     [1, 0, -1] ]) / 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"border:3px; border-style:solid; border-color:#FF0000; padding: 1em;\">You may often see this filter kernel written with the first and third columns swapped.  This is appropriate if you perform correlation, not convolution. These are two similar operations but differ in the kernel being reflected about its centre.  Many kernels are symmetric which means that convolution and correlation are the same.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = Image.Read('penguins.png', grey=True, dtype='float')\n",
    "penguins.disp();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_horizontal = penguins.convolve(kernel)\n",
    "gradient_horizontal.disp(colormap='signed');                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is displayed with a color map that shows negative numbers as red and positive numbers as blue.  Zoom in on the outline of the \"P\" (use the second button from the right in the bottom toolbar) and you can see that the intensity goes up (blue) on the left side of the \"P\", from the grey background to the white paint. It goes down (red) on right of the stem, from the white paint to the gray background.\n",
    "\n",
    "<p style=\"border:3px; border-style:solid; border-color:#FF0000; padding: 1em;\">Our original image comprised unsigned integers (uint8) which are unable to express negative values.  The output of convolve() is a signed floating point image meaning the result at each pixel, can be positive or negative.</p>\n",
    "\n",
    "We can find the horizontal edges by finding vertical gradient, using the transpose of the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_vertical = penguins.convolve(kernel.T)\n",
    "gradient_vertical.disp(colormap='signed');    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RVSS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

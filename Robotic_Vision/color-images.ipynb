{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://github.com/rvss-australia/RVSS/blob/main/Pics/RVSS-logo-col.med.jpg?raw=1\" width=\"400\"></td>\n",
    "    <td><div align=\"left\"><font size=\"30\">Color images</font></div></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "(c) Peter Corke 2024\n",
    "\n",
    "Robotics, Vision & Control: Python, see Chapter 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Jupyter environment\n",
    "We need to import some packages to help us with linear algebra (`numpy`), graphics (`matplotlib`), and machine vision (`machinevisiontoolbox`).\n",
    "If you're running locally you need to have these packages installed.  If you're running on CoLab we have to first install machinevisiontoolbox which is not preinstalled, this will be a bit slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    print('Running on CoLab')\n",
    "    !pip install machinevision-toolbox-python\n",
    "    COLAB = True\n",
    "except:\n",
    "    COLAB = False\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from machinevisiontoolbox import *\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# display result of assignments\n",
    "if COLAB:\n",
    "    %config ZMQInteractiveShell.ast_node_interactivity = 'last_expr_or_assign'\n",
    "# make NumPy display a bit nicer\n",
    "np.set_printoptions(linewidth=100, formatter={'float': lambda x: f\"{x:10.4g}\" if abs(x) > 1e-10 else f\"{0:10.4g}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color planes\n",
    "We will read a color image into a Python object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.Read(\"flowers4.png\")\n",
    "# image = Image.Read(\"flowers8.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the image is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that is, it is 640x426.\n",
    "\n",
    "We can pull out the NumPy array that holds the pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = image.image\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is simply a big 3-dimensional array of 8-bit integers.  We can consider this as a stack of 2-dimensional tables each of shape (426,640) and we refer to these as color planes. The planes correspond to the colors red, green and blue, and the elements vary between 0 (zero amount of the corresponding color) and 255 (maximum amount of the corresponding color)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this clearer, we can access the value of the pixel at image coordinate (516,351), remember that's (horizontal, vertical) coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[516,351]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is a 3-element 1-dimensional array with `uint8` values.  This is the intensity of red, green and blue respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Q: what color is this pixel?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"border:3px; background-color:#FF0000; font-weight: bold; padding: 1em; text-align: center;\">Internally the color images are stored in OpenCV's default color order which is blue, green, red.  This is the opposite of almost everything else in the world which works with a color order of red, green and blue (RGB).  The Toolbox hides OpenCV idiosyncrasies.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a lot of pertinant information about the image by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which says that the image contains 3 \"color planes\" named R, G and B, and each plane is 640x426.\n",
    "\n",
    "And, we can display it as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.disp();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw earlier, the image view is interactive. As you move the cursor over the image, the pixel coordinates and value are updated at the bottom of the window.  The displayed pixel values are always in the range 0 to 255 which are minimum and maximum possible values for the `uint8` pixel data type.\n",
    "\n",
    "A toolbar provides some extra functionality.  You can select a region to get an expanded view, pan that selected region around, change the zoom level, or revert to the original view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: move the cursor over the image and see the pixel values at the bottom right.  Use the buttons with the square in it to select a region of interest (click the button, then click and drag a rectangle in the image window, the home button restores the original view). How do the pixel values vary as you explore different colored flowers?  (there are some very small blue flowers)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color planes\n",
    "\n",
    "We can also think of the color image as a stack of three greyscale images that each represent the amoung of redness, greenness and blueness (effectively what the scene looks like through a red, green or blue filter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can have images with 2, 3, 4 or more planes.  Hyperspectral cameras can \"see\" uptp 20 colors (often called bands, short for spectral bands).  The number of planes in the image is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.nplanes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some images might have 3 planes but they represent hue, saturation and intensity, rather than red, green and blue. The names of the planes, and which \"layer\" in the 3D-array they are in is given by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.colororder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's let more closely at one of these color planes -- the red plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = image.red()\n",
    "red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we see that is a greyscale image.  The intensity of each pixel is the amount of red at the corresponding pixel in the original color image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red.disp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: why are red flowers so dark in this image?**\n",
    "\n",
    "**Q: why are the white and yellow flowers so bright in this image?**\n",
    "\n",
    "**Q: display the green and blue planes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also have written `image.plane(0)`, `image.plane(\"R\")`, or `image[0]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greyscale and color conversion\n",
    "\n",
    "We can convert a color image to a greyscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.mono().disp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the greyscale value is a weighted average of the red, greend and blue values.  The hightest weighting is for green and the lowest weighting is for blue, to match the response of the human eye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also colorize the red plane image from above. Here we say that the red value is equal to the corresponding greyscale value, while green and blue are set to zero.  The result is a color image, but the only color is red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red.colorize([1,0,0]).disp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms\n",
    "\n",
    "Often we are interested to know the distribution of the pixel values in each plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which shows that the pixels span the full range from 0 to 255.  A histogram provides more nuanced information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = image.hist()\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "hist.plot(type=\"frequency\", style=\"stack\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the blue channel has a large number of 0 values. We also see that all channels are overexposed, a large number of pixels have the maximum value of 255.\n",
    "\n",
    "**Q: where are these overexposed pixels in the image?**\n",
    "\n",
    "**Q: where are all the pixels with zero amounts of blue?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RVSS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
